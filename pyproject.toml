[tool.poetry]
name = "llm-observability-workshop"
version = "1.0.0"
description = "A minimal, workshop-ready Python API for LLM integration with Ollama and Azure OpenAI"
authors = ["Joaquin Rodriguez <your-email@example.com>"]
readme = "README.md"
packages = [{include = "apps"}]

[tool.poetry.dependencies]
python = "^3.11"
fastapi = "^0.115.0"
uvicorn = {extras = ["standard"], version = "^0.32.0"}
pydantic = "^2.9.0"
pydantic-settings = "^2.6.0"
python-dotenv = "^1.0.1"
langchain-core = "^0.3.15"
langchain-openai = "^0.2.3"
langchain-ollama = "^0.2.0"
httpx = "^0.27.0"
traceloop-sdk = "^0.43.1"

[tool.poetry.group.pii]
optional = true

[tool.poetry.group.pii.dependencies]
presidio-analyzer = "^2.2.0"
presidio-anonymizer = "^2.2.0"
spacy = "^3.7.0"

[tool.poetry.group.dev.dependencies]
pytest = "^8.3.0"
pytest-asyncio = "^0.24.0"
black = "^24.10.0"
isort = "^5.13.0"
flake8 = "^7.1.0"
pytest-cov = "^5.0.0"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.black]
line-length = 88
target-version = ['py311']
include = '\.pyi?$'
extend-exclude = '''
/(
  # directories
  \.eggs
  | \.git
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | build
  | dist
)/
'''

[tool.isort]
profile = "black"
multi_line_output = 3
line_length = 88
include_trailing_comma = true
force_grid_wrap = 0
use_parentheses = true
ensure_newline_before_comments = true

[tool.pytest.ini_options]
testpaths = ["tests", "."]
python_files = ["test_*.py", "*_test.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = "-v --tb=short"
asyncio_mode = "auto"